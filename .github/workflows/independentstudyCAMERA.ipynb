{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.44 ðŸš€ Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6064MiB)\n",
      "Setup complete âœ… (12 CPUs, 15.6 GB RAM, 87.4/915.8 GB disk)\n",
      "/home/independent-study/Desktop\n",
      "mkdir: cannot create directory â€˜datasetsâ€™: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/independent-study/independentstudyethan/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/independent-study/Desktop/datasets\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import ipywidgets as widgets\n",
    "import threading as thread\n",
    "import time\n",
    "import traitlets\n",
    "import dataset\n",
    "from uuid import uuid1\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "model = YOLO('yolo11q.pt')\n",
    "model2 = YOLO('yolo11s.pt')\n",
    "\n",
    "%cd {HOME}\n",
    "!mkdir datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "ROBOFLOW_API_KEY = ('14W8hOR0bWFloIDQecFa')\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project2 = rf.workspace(\"screw-sorting-project\").project(\"side-screw-sorter\")\n",
    "version2 = project2.version(4)\n",
    "dataset2 = version2.download(\"yolov11\")\n",
    "\n",
    "project = rf.workspace(\"screw-sorting-project\").project(\"screw-sorting\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov11\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/11/25 10:14:53] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.29</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> is out of date! Please upgrade to <a href=\"file:///home/independent-study/independentstudyethan/lib/python3.12/site-packages/inference/core/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/independent-study/independentstudyethan/lib/python3.12/site-packages/inference/core/__init__.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.46</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of inference for the latest features and bug fixes by    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/11/25 10:14:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Your inference package version \u001b[1;36m0.29\u001b[0m.\u001b[1;36m2\u001b[0m is out of date! Please upgrade to \u001b]8;id=13062;file:///home/independent-study/independentstudyethan/lib/python3.12/site-packages/inference/core/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=827709;file:///home/independent-study/independentstudyethan/lib/python3.12/site-packages/inference/core/__init__.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version \u001b[1;36m0.46\u001b[0m.\u001b[1;36m4\u001b[0m of inference for the latest features and bug fixes by    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         running `pip install --upgrade inference`.                              \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'CoreMLExecutionProvider' is not in available provider names.Available providers: 'TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adef2443f6e04acbad4116ff43eb00b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='360', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7014825861be4f39b9abdf13ce15c0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='360', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread started\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "Detections:\n",
      "thread stopped\n",
      "all threads terminated\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import torch\n",
    "import inference\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "stop_event = thread.Event()\n",
    "stop_cap_event = thread.Event()\n",
    "stop_cap1_event = thread.Event()\n",
    "\n",
    "# Select the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize Model\n",
    "model_id = project.id.split(\"/\")[1] + \"/\" + dataset.version\n",
    "model_id2 = project2.id.split(\"/\")[1] + \"/\" + dataset2.version\n",
    "model = inference.get_model(model_id, '14W8hOR0bWFloIDQecFa')\n",
    "model2 = inference.get_model(model_id2, '14W8hOR0bWFloIDQecFa')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # First webcamcombined_labels_array = sorted(combined_labels_array2, key=lambda x: x[2])\n",
    "cap2 = cv2.VideoCapture(2)  # Second webcam\n",
    "focus = 0  # min: 0, max: 255, increment:5\n",
    "cap2.set(28, focus) \n",
    "\n",
    "# Image widgets for displaying frames\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=360)\n",
    "image_widget2 = widgets.Image(format='jpeg', width=640, height=360)\n",
    "display(image_widget, image_widget2)\n",
    "\n",
    "# Queue to store frames\n",
    "frame_queue = Queue(maxsize=5)\n",
    "frame_queue2 = Queue(maxsize=5)\n",
    "\n",
    "\n",
    "\n",
    "# Frame capture function for the first webcam\n",
    "def capture_frames():\n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 50)\n",
    "    while not stop_cap_event.is_set():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam 1.\")\n",
    "            break\n",
    "        if not frame_queue.full():\n",
    "            frame_queue.put(frame)\n",
    "    cap.release()\n",
    "\n",
    "# Frame capture function for the second webcam\n",
    "def capture_frames1():\n",
    "    cap2.set(cv2.CAP_PROP_FOCUS, 50)\n",
    "    while not stop_cap1_event.is_set():\n",
    "        ret, frame2 = cap2.read()\n",
    "        frame2 = cv2.flip(frame2, 1)\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam 2.\")\n",
    "            break\n",
    "        if not frame_queue2.full():\n",
    "            frame_queue2.put(frame2)\n",
    "    cap2.release()\n",
    "\n",
    "# Frame processing and inference function\n",
    "xCoordinate = 0\n",
    "xCoordinate2 = 0\n",
    "labels2 = [2]\n",
    "combinedLabelsSide = np.array([])\n",
    "combinedLabelsSide2 = np.array([])\n",
    "combined_labels_array = []  # Initialize a 2D array to store the results\n",
    "combined_labels_array2 = []  # Initialize a 2D array to store the results\n",
    "complete_labels_array =[]\n",
    "filtered_detections =[]\n",
    "def process_and_display():\n",
    "    global xCoordinate\n",
    "    global xCoordinate2\n",
    "    global labels2\n",
    "    global combinedLabelsSide\n",
    "    global combinedLabelsSide2\n",
    "    global combined_labels_array\n",
    "    global combined_labels_array2\n",
    "    global complete_labels_array\n",
    "    global filtered_detections\n",
    "    print(\"Thread started\")\n",
    "    while not stop_event.is_set():\n",
    "        # Process first webcam frames\n",
    "        if not frame_queue2.empty():\n",
    "            frame2 = frame_queue2.get()\n",
    "            results = model2.infer(frame2, confidence=0.4, overlap=0.3)[0]\n",
    "            detections2 = sv.Detections.from_inference(results)\n",
    "            if detections2.xyxy.size != 0:\n",
    "                combined_labels_array = []  # Initialize a 2D array to store the results\n",
    "                for i in range(len(detections2.xyxy)):\n",
    "                    labels2 = detections2.data.get('class_name', None)\n",
    "                    xCoordinate2 = (detections2.xyxy[i][2] + detections2.xyxy[i][0]) / 2\n",
    "                    for n in range(len(detections2.xyxy)):\n",
    "                        if n != i:\n",
    "                            other_x_coordinate = (detections2.xyxy[n][2] + detections2.xyxy[n][0]) / 2\n",
    "                            if abs(xCoordinate2 - other_x_coordinate) <= 7:\n",
    "                                combinedLabelsSide = [xCoordinate2, labels2[i], labels2[n]]\n",
    "                                combinedLabelsSide.sort(key=repr)  # Sort combinedLabelsSide\n",
    "                                combined_labels_array.append(combinedLabelsSide)  # Add to 2D array\n",
    "                                combined_labels_array = sorted(combined_labels_array, key=lambda x: x[2])\n",
    "                                n = len(detections2.xyxy)  # Break inner loop\n",
    "            # Annotate boxes and labels\n",
    "            box_annotator = sv.BoxAnnotator()\n",
    "            #label_annotator = sv.LabelAnnotator()\n",
    "            annotated_frame2 = box_annotator.annotate(scene=frame2, detections=detections2)\n",
    "            #annotated_frame2 = label_annotator.annotate(scene=annotated_frame2, detections=detections2)\n",
    "            _, jpeg2 = cv2.imencode('.jpg', annotated_frame2)\n",
    "            image_widget2.value = jpeg2.tobytes()\n",
    "\n",
    "\n",
    "        #run = 0\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            results = model.infer(frame, confidence=0.4, overlap=0.3)[0]\n",
    "            detections = sv.Detections.from_inference(results)\n",
    "            if detections.xyxy.size != 0:\n",
    "                combined_labels_array2 = []  # Initialize a 2D array to store the results\n",
    "                for i in range(len(detections.xyxy)):\n",
    "                    labels2 = detections.data.get('class_name', None)\n",
    "                    xCoordinate2 = (detections.xyxy[i][2] + detections.xyxy[i][0]) / 2\n",
    "                    combinedLabelsSide2 = [labels2[i], xCoordinate2]\n",
    "                    combined_labels_array2.append(combinedLabelsSide2)  # Add to 2D array\n",
    "                    combined_labels_array2.sort(key=lambda x: x[1])\n",
    "            # Annotate boxes and labels\n",
    "            box_annotator = sv.BoxAnnotator()\n",
    "            #label_annotator = sv.LabelAnnotator()\n",
    "            annotated_frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "            #annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "            # Update the widget\n",
    "            _, jpeg = cv2.imencode('.jpg', annotated_frame)\n",
    "            image_widget.value = jpeg.tobytes()   \n",
    "\n",
    "        if((len(combined_labels_array))>0):\n",
    "            filtered_detections = []\n",
    "            for detection in combined_labels_array:\n",
    "                if not filtered_detections or abs(detection[2] - filtered_detections[-1][2]) >= 6:\n",
    "                    filtered_detections.append(detection)\n",
    "\n",
    "        # print(\"legnth of 1d array:\", len(combined_labels_array2))\n",
    "        # print(\"legnth of 2d array:\", len(filtered_detections))\n",
    "        if len(combined_labels_array2) == len(filtered_detections):\n",
    "            print(\"Detections:\")\n",
    "            for i in range(len(combined_labels_array2)):  # Use range to iterate by index\n",
    "                # Append a tuple or list to complete_labels_array\n",
    "                complete_labels_array.append([\n",
    "                    filtered_detections[i][0],  # First element from filtered_detections\n",
    "                    filtered_detections[i][1],  # Second element from filtered_detections\n",
    "                    combined_labels_array2[i][0],  # First element from combined_labels_array2\n",
    "                    filtered_detections[i][2]   # Third element from filtered_detections\n",
    "                ])\n",
    "            for detection in complete_labels_array:\n",
    "                    print(detection)\n",
    "            complete_labels_array = []\n",
    "\n",
    "\n",
    "    frame_queue2.empty()\n",
    "    frame_queue.empty()\n",
    "    # Release cameras when done\n",
    "    print(\"thread stopped\")\n",
    "\n",
    "# Start the capture and processing threads\n",
    "# capture_thread = Thread(target=capture_frames)\n",
    "# capture_thread1 = Thread(target=capture_frames1)\n",
    "# process_thread = Thread(target=process_and_display)\n",
    "\n",
    "def start_process_thread():\n",
    "    global process_thread\n",
    "    stop_event.clear()  # Clear the stop event to allow the thread to run\n",
    "    process_thread = Thread(target=process_and_display)\n",
    "    process_thread.start()\n",
    "\n",
    "def start_capture_thread():\n",
    "    global capture_thread\n",
    "    stop_cap_event.clear()  # Clear the stop event to allow the thread to run\n",
    "    capture_thread = Thread(target=capture_frames)\n",
    "    capture_thread.start()\n",
    "\n",
    "def start_capture1_thread():\n",
    "    global capture_thread1\n",
    "    stop_cap1_event.clear()  # Clear the stop event to allow the thread to run\n",
    "    capture_thread1 = Thread(target=capture_frames1)\n",
    "    capture_thread1.start()\n",
    "\n",
    "\n",
    "def stop_process_thread():\n",
    "    stop_event.set()  # Signal the thread to stop\n",
    "    process_thread.join()     # Wait for the thread to finish\n",
    "\n",
    "def stop_capture_thread():\n",
    "    stop_cap_event.set()  # Signal the thread to stop\n",
    "    capture_thread.join()     # Wait for the thread to finish\n",
    "\n",
    "def stop_capture1_thread():\n",
    "    stop_cap1_event.set()  # Signal the thread to stop\n",
    "    capture_thread1.join()     # Wait for the thread to finish\n",
    "\n",
    "start_capture_thread() \n",
    "start_capture1_thread()\n",
    "time.sleep(3)   # Let it run for a while\n",
    "\n",
    "start_process_thread()  # Start the thread\n",
    "time.sleep(10)   # Let it run for a while\n",
    "stop_process_thread()   # Stop the thread\n",
    "# time.sleep(2)   # Let it run for a while\n",
    "\n",
    "# start_process_thread()  # Restart the thread\n",
    "# time.sleep(3)   # Let it run for a while\n",
    "# stop_process_thread()   # Stop it again\n",
    "# time.sleep(2)   # Let it run for a while\n",
    "\n",
    "# start_process_thread()  # Restart the thread\n",
    "# time.sleep(3)   # Let it run for a while\n",
    "# stop_process_thread()   # Stop it again\n",
    "# time.sleep(2)   # Let it run for a while\n",
    "\n",
    "\n",
    "\n",
    "stop_capture_thread()\n",
    "stop_capture1_thread()\n",
    "print(\"all threads terminated\")\n",
    "\n",
    "# To stop the loops, set is_running = False in your notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyserial\n",
      "  Using cached pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
      "Installing collected packages: pyserial\n",
      "Successfully installed pyserial-3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyserial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focus control is not supported by this camera.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)  # 0 is the index for the default camera\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the camera.\")\n",
    "    exit()\n",
    "\n",
    "# Set camera properties\n",
    "focus = 10 # min: 0, max: 255, increment:5\n",
    "if not cap.set(28, focus):\n",
    "    print(\"Focus control is not supported by this camera.\")\n",
    "else:\n",
    "    print(f\"Focus set to {focus}\")\n",
    "\n",
    "# Capture frames\n",
    "while True:\n",
    "    cap.set(28, focus)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    # Break the loop on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (independentstudyethan)",
   "language": "python",
   "name": "independentstudyethan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
