{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import ipywidgets as widgets\n",
    "import threading as thread\n",
    "import time\n",
    "import traitlets\n",
    "import dataset\n",
    "import os\n",
    "from uuid import uuid1\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create image widgets for displaying video feeds\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=360)\n",
    "image_widget2 = widgets.Image(format='jpeg', width=640, height=360)\n",
    "on = False\n",
    "\n",
    "# Initialize video capture for two cameras with lower resolution and FPS\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(cv2.CAP_PROP_FPS, 15)\n",
    "\n",
    "#cap2 = cv2.VideoCapture(1)\n",
    "#cap2.set(cv2.CAP_PROP_FPS, 15)\n",
    "\n",
    "# Create a toggle button to start/stop the feed\n",
    "toggle_button = widgets.ToggleButton(value=False, description='Start/Stop Video')\n",
    "\n",
    "# Frame queues for reducing latency\n",
    "frame_queue = queue.Queue(maxsize=1)\n",
    "frame_queue2 = queue.Queue(maxsize=1)\n",
    "\n",
    "# Frame update function for the first camera\n",
    "def update_image():\n",
    "    global on\n",
    "    while on:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Add the latest frame to the queue, replacing the old one\n",
    "            if not frame_queue.empty():\n",
    "                frame_queue.get_nowait()\n",
    "            frame_queue.put_nowait(frame)\n",
    "\n",
    "# Frame update function for the second camera\n",
    "def update_image2():\n",
    "    global on\n",
    "    while on:\n",
    "        ret2, frame2 = cap2.read()\n",
    "        if ret2:\n",
    "            if not frame_queue2.empty():\n",
    "                frame_queue2.get_nowait()\n",
    "            frame_queue2.put_nowait(frame2)\n",
    "\n",
    "# Display function to update widgets\n",
    "def display_image():\n",
    "    global on\n",
    "    while on:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get_nowait()\n",
    "            success, jpeg = cv2.imencode('.jpeg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "            if success:\n",
    "                image_widget.value = jpeg.tobytes()\n",
    "        if not frame_queue2.empty():\n",
    "            frame2 = frame_queue2.get_nowait()\n",
    "            success, jpeg2 = cv2.imencode('.jpeg', frame2, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "            if success:\n",
    "                image_widget2.value = jpeg2.tobytes()\n",
    "\n",
    "# Start/stop the video feed\n",
    "def toggle_video(change):\n",
    "    global on\n",
    "    if change['new']:\n",
    "        on = True\n",
    "        toggle_button.description = 'Stop Video'\n",
    "        display(image_widget, image_widget2)\n",
    "        \n",
    "        # Start camera threads\n",
    "        threading.Thread(target=update_image).start()\n",
    "        threading.Thread(target=update_image2).start()\n",
    "        \n",
    "        # Start display thread\n",
    "        threading.Thread(target=display_image).start()\n",
    "    else:\n",
    "        on = False\n",
    "        toggle_button.description = 'Start Video'\n",
    "        \n",
    "        # Release video captures and clear outputs\n",
    "        cap.release()\n",
    "        cap2.release()\n",
    "        clear_output()\n",
    "        display(toggle_button)\n",
    "\n",
    "# Observe button toggle to start/stop video feed\n",
    "toggle_button.observe(toggle_video, 'value')\n",
    "\n",
    "# Display the button\n",
    "display(toggle_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a directory for storing data\n",
    "def create_data_dirs(classes, root_dir='independentstudyjow/datasets/dataset1/data'):\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "\n",
    "    # Create subfolders for each class\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "            print(f\"Created directory: {class_dir}\")\n",
    "\n",
    "# Example classes\n",
    "classes = ['Philips', 'Hex', 'Star', 'Flat']\n",
    "create_data_dirs(classes)\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=classes,\n",
    "    value=classes[0],\n",
    "    description='Class:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to save the image to the directory with the class name\n",
    "# def save_snapshot(directory):\n",
    "#     image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "#     with open(image_path, 'wb') as f:\n",
    "#         f.write(image_widget.value)\n",
    "\n",
    "def save_snapshot(class_name):\n",
    "    root_dir = 'independentstudyjow/datasets/dataset1/data/'\n",
    "    directory = os.path.join(root_dir,class_name+\"/\"+str(uuid1())+'.jpg')\n",
    "    # Save image from widget's byte data\n",
    "    with open(directory, \"wb\") as f:\n",
    "        f.write(image_widget.value)  # Save widget image data directly\n",
    "    \n",
    "    print(f'Saved: {directory}')\n",
    "\n",
    "def save_snapshot2(class_name):\n",
    "    root_dir = 'independentstudyjow/datasets/dataset1/data/'\n",
    "    directory = os.path.join(root_dir,class_name+\"/\"+str(uuid1())+'.jpg')\n",
    "    # Save image from widget's byte data\n",
    "    with open(directory, \"wb\") as f:\n",
    "        f.write(image_widget2.value)  # Save widget image data directly\n",
    "    \n",
    "    print(f'Saved: {directory}')\n",
    "\n",
    "# Step 5: Capture images based on dropdown value (class label)\n",
    "def on_dropdown_change(change):\n",
    "    selected_class = change['new']\n",
    "    print(f\"Selected class: {selected_class}\")\n",
    "\n",
    "# Step 6: Connect the dropdown widget to the function\n",
    "dropdown.observe(on_dropdown_change, names='value')\n",
    "\n",
    "# Display the dropdown and image widgets\n",
    "camera_widget = widgets.HBox([\n",
    "image_widget,image_widget2\n",
    "])\n",
    "display(camera_widget)\n",
    "\n",
    "# Save the dataset with buttons\n",
    "def on_save_button_clicked(b):\n",
    "    selected_class = dropdown.value\n",
    "    if image_widget.value:  # If an image is loaded in the widget\n",
    "        save_snapshot(selected_class)\n",
    "    else:\n",
    "        print(\"No image to save!\")\n",
    "\n",
    "def on_save_button_clicked2(b):\n",
    "    selected_class = dropdown.value\n",
    "    if image_widget2.value:  # If an image is loaded in the widget\n",
    "        save_snapshot2(selected_class)\n",
    "    else:\n",
    "        print(\"No image to save!\")\n",
    "\n",
    "# Create save button\n",
    "save_button = widgets.Button(description='Save Image')\n",
    "save_button.on_click(on_save_button_clicked)\n",
    "save_button2 = widgets.Button(description='Save Image 2nd Cam')\n",
    "save_button2.on_click(on_save_button_clicked2)\n",
    "# Add count widgets for specific class (Optional)\n",
    "data_collection_widget = widgets.VBox([\n",
    "    widgets.HBox([save_button, save_button2]),\n",
    "    dropdown\n",
    "])\n",
    "\n",
    "display(data_collection_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import ipywidgets as widgets\n",
    "import threading as thread\n",
    "import time\n",
    "import traitlets\n",
    "import dataset\n",
    "from uuid import uuid1\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "model = YOLO('yolo11q.pt')\n",
    "model2 = YOLO('yolo11s.pt')\n",
    "\n",
    "%cd {HOME}\n",
    "!mkdir datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "ROBOFLOW_API_KEY = ('14W8hOR0bWFloIDQecFa')\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project2 = rf.workspace(\"screw-sorting-project\").project(\"side-screw-sorter\")\n",
    "version2 = project2.version(4)\n",
    "dataset2 = version2.download(\"yolov11\")\n",
    "\n",
    "project = rf.workspace(\"screw-sorting-project\").project(\"screw-sorting\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov11\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=train model=yolo11s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "IPyImage(filename=f'{HOME}/runs/detect/train5/val_batch0_pred.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=val model={HOME}/runs/detect/train5/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model={HOME}/runs/detect/train5/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import torch\n",
    "import inference\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Select the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize Model\n",
    "model_id = project.id.split(\"/\")[1] + \"/\" + dataset.version\n",
    "model_id2 = project2.id.split(\"/\")[1] + \"/\" + dataset2.version\n",
    "model = inference.get_model(model_id, '14W8hOR0bWFloIDQecFa')\n",
    "model2 = inference.get_model(model_id2, '14W8hOR0bWFloIDQecFa')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # First webcam\n",
    "cap2 = cv2.VideoCapture(2)  # Second webcam\n",
    "\n",
    "# Image widgets for displaying frames\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=360)\n",
    "image_widget2 = widgets.Image(format='jpeg', width=640, height=360)\n",
    "display(image_widget, image_widget2)\n",
    "\n",
    "# Queue to store frames\n",
    "frame_queue = Queue(maxsize=5)\n",
    "frame_queue2 = Queue(maxsize=5)\n",
    "\n",
    "# Flag to control the webcam loop\n",
    "is_running = True\n",
    "\n",
    "# Frame capture function for the first webcam\n",
    "def capture_frames():\n",
    "    global is_running\n",
    "    while is_running:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam 1.\")\n",
    "            break\n",
    "        if not frame_queue.full():\n",
    "            frame_queue.put(frame)\n",
    "\n",
    "# Frame capture function for the second webcam\n",
    "def capture_frames1():\n",
    "    global is_running\n",
    "    while is_running:\n",
    "        ret, frame2 = cap2.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam 2.\")\n",
    "            break\n",
    "        if not frame_queue2.full():\n",
    "            frame_queue2.put(frame2)\n",
    "\n",
    "# Frame processing and inference function\n",
    "xCoordinate = 0\n",
    "yCoordinate = 0\n",
    "labels = 0\n",
    "xCoordinate2 = 0\n",
    "yCoordinate2 = 0\n",
    "labels2 = 0\n",
    "def process_and_display():\n",
    "    global is_running\n",
    "    global xCoordinate\n",
    "    global yCoordinate\n",
    "    global labels\n",
    "    global xCoordinate2\n",
    "    global yCoordinate2\n",
    "    global labels2\n",
    "    while is_running:\n",
    "        # Process first webcam frames\n",
    "        if not frame_queue.empty:\n",
    "            frame = frame_queue.get()\n",
    "            results = model.infer(frame, confidence=0.4, overlap=0.3)[0]\n",
    "            detections = sv.Detections.from_inference(results)\n",
    "            # Annotate boxes and labels\n",
    "            box_annotator = sv.BoxAnnotator()\n",
    "            label_annotator = sv.LabelAnnotator()\n",
    "            annotated_frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "            annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "            # Update the widget\n",
    "            _, jpeg = cv2.imencode('.jpg', annotated_frame)\n",
    "            image_widget.value = jpeg.tobytes()\n",
    "\n",
    "        if not frame_queue2.empty():\n",
    "            frame2 = frame_queue2.get()\n",
    "            results = model2.infer(frame2, confidence=0.4, overlap=0.3)[0]\n",
    "            detections2 = sv.Detections.from_inference(results)\n",
    "            # Annotate boxes and labels\n",
    "            box_annotator = sv.BoxAnnotator()\n",
    "            label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "            annotated_frame2 = box_annotator.annotate(scene=frame2, detections=detections2)\n",
    "            annotated_frame2 = label_annotator.annotate(scene=annotated_frame2, detections=detections2)\n",
    "            _, jpeg2 = cv2.imencode('.jpg', annotated_frame2)\n",
    "            image_widget2.value = jpeg2.tobytes()\n",
    "\n",
    "            \n",
    "            if(detections2.xyxy.size != 0&detections.xyxy.size != 0):\n",
    "                print(\"Detections: \")\n",
    "                for i in range(len(detections2.xyxy)):\n",
    "                    labels2 = detections2.data.get('class_name', None)\n",
    "                    xCoordinate2 = (detections2.xyxy[i][2]+detections2.xyxy[i][0])/2\n",
    "                    yCoordinate2 = (detections2.xyxy[i][3]+detections2.xyxy[i][1])/2\n",
    "                    for n in range(len(detections2.xyxy)):\n",
    "                        if(n!=i):\n",
    "                            if(abs(((detections2.xyxy[i][2]+detections2.xyxy[i][0])/2)-((detections2.xyxy[n][2]+detections2.xyxy[n][0])/2))<=5):\n",
    "                                print(\"x: \", xCoordinate2, \"y: \", yCoordinate2, labels2[i], labels2[n])\n",
    "                        for s in range(len(detections.xyxy)):\n",
    "                            if(s!=i):\n",
    "                                if(abs(((detections.xyxy[i][2]+detections.xyxy[i][0])/2)-((detections2.xyxy[s][2]+detections2.xyxy[s][0])/2))<=5):\n",
    "                                    print(\"x: \", xCoordinate, \"y: \", yCoordinate, labels[s],labels2[i], labels2[n])\n",
    "                        n=len(detections2.xyxy)\n",
    "\n",
    "                        \n",
    "        print(\"match not found\")\n",
    "    \n",
    "\n",
    "    # Release cameras when done\n",
    "    cap.release()\n",
    "    cap2.release()\n",
    "    print(\"Webcam feed stopped.\")\n",
    "\n",
    "# Start the capture and processing threads\n",
    "capture_thread = Thread(target=capture_frames)\n",
    "capture_thread1 = Thread(target=capture_frames1)\n",
    "process_thread = Thread(target=process_and_display)\n",
    "\n",
    "capture_thread.start()\n",
    "capture_thread1.start()\n",
    "process_thread.start()\n",
    "\n",
    "# To stop the loops, set is_running = False in your notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "# Test GPU usage\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using device:\", device)\n",
    "    tensor = torch.rand(3, 3).to(device)\n",
    "    print(\"Tensor allocated on:\", tensor.device)\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your installation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "independentstudyethan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
